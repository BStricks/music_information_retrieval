{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_webscrape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BStricks/music_information_retrieval/blob/master/music_webscrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsbXsrFojHs",
        "colab_type": "text"
      },
      "source": [
        "# Web scraping the album review corpus\n",
        "\n",
        "The primary purpose of this script is to crawl the pitchfork.com website for all album reviews and download the review text into a dataframe along with the artist and album name attributes. This methodology can be extended to include multiple other domains e.g. amazon reviews, rolling stone etc.\n",
        "\n",
        "The secondary purpose was to trial a document matching algorithm on the newly created corpus; using a range of matching techniques the aim is to match a user's natuaral language query with the most appropriate album. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrMFbZgGqZy5",
        "colab_type": "text"
      },
      "source": [
        "# Section 1: web scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxCUMWqSUJcM",
        "colab_type": "code",
        "outputId": "2b16e88a-b414-4b59-894b-97a12d5b0837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "###mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "###change directory\n",
        "%cd gdrive/My Drive/Colab Notebooks/album_reviews"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/Colab Notebooks/album_reviews'\n",
            "/content/gdrive/My Drive/Colab Notebooks/album_reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGqpZUym6uHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import pickle\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbf5fJN5mOGI",
        "colab_type": "text"
      },
      "source": [
        "## Pitchfork scrape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9iLsRmI7dQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###webpages to scrape\n",
        "pagelist = []\n",
        "for i in range(1, 50):\n",
        "  pagelist.append('https://pitchfork.com/reviews/albums/?page='+str(i))\n",
        "\n",
        "###create table for hyperlinks\n",
        "master_table_pitchfork = pd.DataFrame(columns=['href', 'artist', 'album'])\n",
        "\n",
        "###function to scrape hyperlinks and extract artist/album tags\n",
        "for i in pagelist:\n",
        "\n",
        "  page = requests.get(i)\n",
        "  soup = BeautifulSoup(page.text, 'html.parser').find_all('div', attrs={\"class\":\"review\"})\n",
        "\n",
        "  for div in soup:\n",
        "    href = ['https://pitchfork.com/'+div.find('a',attrs={\"class\":\"review__link\"})['href']]\n",
        "    artist = [div.find('li').text]\n",
        "    album = [div.find('h2').text]\n",
        "\n",
        "    new_table = pd.DataFrame(\n",
        "        {'href': href,\n",
        "        'artist': artist,\n",
        "        'album': album\n",
        "        })\n",
        "\n",
        "    master_table_pitchfork = master_table_pitchfork.append(new_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CA3MaBPWMfkz",
        "colab": {}
      },
      "source": [
        "###scrape webpage for album review text\n",
        "review_text = []\n",
        "\n",
        "for i in range(0,588):\n",
        "  \n",
        "  href = master_table_pitchfork.iloc[i][0]\n",
        "  page = requests.get(href)\n",
        "\n",
        "  if not page:\n",
        "    review_text.append(\"NULL\")\n",
        "\n",
        "  else: \n",
        "    soup = BeautifulSoup(page.text, 'html.parser').find_all('div', attrs={\"class\":\"contents\"})\n",
        "  \n",
        "    for div in soup:\n",
        "    \n",
        "      if div.text:\n",
        "        review_text.append(div.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqOCbFFGHMrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "master_table_pitchfork = master_table_pitchfork.assign(review_text=review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9294pxEDmgvL",
        "colab_type": "text"
      },
      "source": [
        "## NME scrape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clpebcswmjsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###webpages to scrape\n",
        "pagelist = []\n",
        "for i in range(1, 2):\n",
        "  pagelist.append('https://www.nme.com/reviews/album/page/'+str(i))\n",
        "\n",
        "###create table for hyperlinks\n",
        "master_table_nme = pd.DataFrame(columns=['href', 'artist','album'])\n",
        "\n",
        "###function to scrape hyperlinks and extract artist/album tags\n",
        "for i in pagelist:\n",
        "\n",
        "  page = requests.get(i)\n",
        "  soup = BeautifulSoup(page.text, 'html.parser').find_all('li', attrs={\"class\":\"listing-item\"})\n",
        "  href = []\n",
        "  artist = []\n",
        "  album = []\n",
        "\n",
        "  for i in soup:\n",
        "    \n",
        "    for a in i.find_all('a'):\n",
        "      href.append(a['href'])\n",
        "\n",
        "    for header in i.find_all(\"h3\"):\n",
        "      header_1 = header.text.strip()\n",
        "      artist1 = header_1.split(' –')[0]\n",
        "      artist.append(artist1)\n",
        "      try: \n",
        "        album1 = header_1.split('\\'')[1]\n",
        "        album2 = album1.split('\\'')[0]\n",
        "        album.append(album2)\n",
        "      except:\n",
        "        album1 = header_1.split('‘')[1]\n",
        "        album2 = album1.split('’')[0]\n",
        "        album.append(album2)\n",
        "\n",
        "new_table = pd.DataFrame({'href': href,'artist': artist,'album': album})\n",
        "\n",
        "master_table_nme = master_table_nme.append(new_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWvyeY3LyNhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(master_table_nme))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOhye95qmqh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###scrape webpage for album review text\n",
        "review_text = []\n",
        "\n",
        "for i in range(0,31):\n",
        "  \n",
        "  href = master_table_nme.iloc[i][0]\n",
        "  page = requests.get(href)\n",
        "\n",
        "  if not page:\n",
        "    review_text.append(\"NULL\")\n",
        "\n",
        "  else: \n",
        "    soup = BeautifulSoup(page.text, 'html.parser').find_all('p')   \n",
        "    sentences = []\n",
        "    for p in soup:\n",
        "        if p.text:\n",
        "          para = str(p.text.strip())\n",
        "          if para.startswith(\"window\"):\n",
        "            pass\n",
        "          elif para.startswith(\"Release\"):\n",
        "            pass\n",
        "          elif para.startswith(\"Record\"):\n",
        "            pass\n",
        "          else:\n",
        "            sentences.append(para)\n",
        "  \n",
        "  review_text.append(' '.join(sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qxB1QK0d99I",
        "colab_type": "code",
        "outputId": "1d2fa3f7-d7f1-46e0-9b7c-36edea08e816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(review_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcw_vEPxrCsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "master_table_nme = master_table_nme.assign(review_text=review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbqBACOOrQoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine\n",
        "master_table = master_table_pitchfork.append(master_table_nme)\n",
        "\n",
        "#pickle\n",
        "outfile = open('album_corpus','wb')\n",
        "pickle.dump(master_table,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}